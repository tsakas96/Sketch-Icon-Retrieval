{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import utils3\n",
    "import model3\n",
    "importlib.reload(utils3)\n",
    "importlib.reload(model3)\n",
    "from utils3 import *\n",
    "from model3 import *\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 1485 samples.\n"
     ]
    }
   ],
   "source": [
    "dic = get_dict_icon_sketches()\n",
    "icons, icons_name_cat = load_icons(dic)\n",
    "sketches, sketch_names_array = load_sketches(dic)\n",
    "\n",
    "sketch_icon_indices, positive_labels = create_positive_sketch_icon_indices(icons_name_cat, sketch_names_array)\n",
    "print(f'We have {len(sketch_icon_indices)} samples.')\n",
    "# shuffle the indices and labels\n",
    "sketch_icon_indices, positive_labels = shuffle(sketch_icon_indices, positive_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  80    2]\n [1341   49]\n [1398   26]\n ...\n [1058   39]\n [ 936   24]\n [1050   17]]\nWe have 2674 samples in the training set.\nWe have 148 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "NEGATIVE_PAIRS_LEN = 1\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "     n_elem = a.shape[0]\n",
    "     indeces = np.random.permutation(n_elem)\n",
    "     return a[indeces], b[indeces]\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, indices, labels):\n",
    "        self.indices = indices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve indices and labels at the given index\n",
    "        indices = self.indices[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return indices, label\n",
    "\n",
    "def create_datasets(sketch_icon_indices, labels, dataset_class, p_train=0.9, p_test=0.1):\n",
    "    len_data = len(sketch_icon_indices)\n",
    "\n",
    "    # Define partition sizes\n",
    "    num_train = int(np.ceil(len_data*p_train))\n",
    "    num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "    sketch_icon_indices_Train, positive_labels_Train = sketch_icon_indices[:num_train], labels[:num_train]\n",
    "    sketch_icon_indices_Test, labels_test = sketch_icon_indices[-num_test:], labels[-num_test:]\n",
    "\n",
    "    negative_indices, negative_labels_Train = create_negative_sketch_icon_indices(sketch_icon_indices_Train, NEGATIVE_PAIRS_LEN)\n",
    "    #print(f'We have {len(sketch_icon_indices_Train)} positive pair samples in the training set.')\n",
    "    #print(f'We have {len(negative_indices)} negative pair samples in the training set.')\n",
    "\n",
    "    negative_array = np.array(negative_indices)\n",
    "    # This array includes the posititive and negative pair indices\n",
    "    pair_indices_Train = np.concatenate((sketch_icon_indices_Train, negative_array), axis=0)\n",
    "    labels_Train = np.concatenate((positive_labels_Train, negative_labels_Train), axis=0)\n",
    "    pair_indices_Train, labels_Train = shuffle_in_unison(pair_indices_Train, labels_Train)\n",
    "\n",
    "    training_set = dataset_class(pair_indices_Train, labels_Train)\n",
    "    test_set = dataset_class(sketch_icon_indices_Test, labels_test)\n",
    "    return training_set, test_set\n",
    "\n",
    "training_set, test_set = create_datasets(sketch_icon_indices, positive_labels, Dataset)   \n",
    "print(f'We have {len(training_set)} samples in the training set.')\n",
    "print(f'We have {len(test_set)} samples in the test set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def load_dataset():\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "      dataset = training_set,\n",
    "      batch_size= batch_size,\n",
    "      num_workers = 0,\n",
    "      shuffle= False\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "      dataset = test_set,\n",
    "      batch_size= batch_size,\n",
    "      num_workers= 0,\n",
    "      shuffle= False\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "margin = 1\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "siameseModel = googlenet()\n",
    "\n",
    "loss = siamese_loss\n",
    "\n",
    "def train_step( icons, sketches , labels, margin):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model1 = siameseModel(icons, training = True)\n",
    "        #print(model1)\n",
    "        model2 = siameseModel(sketches, training = True)    \n",
    "        tape.watch(model1)\n",
    "        tape.watch(model2)\n",
    "        labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "        tape.watch(labels)\n",
    "        current_loss = loss(model1, model2, labels)\n",
    "    grads = tape.gradient(current_loss, siameseModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, siameseModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(148, 224, 224, 3)\n(52, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_icon_indeces = set()\n",
    "test_sketch_indices = set()\n",
    "for s, i in test_set.indices:\n",
    "    test_sketch_indices.add(s)\n",
    "    test_icon_indeces.add(i)\n",
    "\n",
    "test_sketch_list = []\n",
    "test_sketch_name = []\n",
    "for s in test_sketch_indices:\n",
    "    test_sketch_list.append(sketches[s])\n",
    "    test_sketch_name.append(sketch_names_array[s])\n",
    "test_sketches = np.array(test_sketch_list)\n",
    "print(test_sketches.shape)\n",
    "\n",
    "test_icon_list = []\n",
    "test_icon_name = []\n",
    "for i in test_icon_indeces:\n",
    "    test_icon_list.append(icons[i])\n",
    "    test_icon_name.append(icons_name_cat[i][0])\n",
    "test_icons = np.array(test_icon_list)\n",
    "print(test_icons.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: Loss: 5.208\n",
      "Accuracy of top 1: 0.02027027027027027\n",
      "Accuracy of top 10: 0.18243243243243243\n",
      "Epoch 1: Loss: 4.967\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.20270270270270271\n",
      "Epoch 2: Loss: 4.915\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.20270270270270271\n",
      "Epoch 3: Loss: 4.918\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 4: Loss: 4.972\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 5: Loss: 4.956\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.21621621621621623\n",
      "Epoch 6: Loss: 4.951\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 7: Loss: 4.912\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.19594594594594594\n",
      "Epoch 8: Loss: 4.943\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.19594594594594594\n",
      "Epoch 9: Loss: 4.910\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.19594594594594594\n",
      "Epoch 10: Loss: 4.922\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 11: Loss: 4.914\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 12: Loss: 4.926\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.1891891891891892\n",
      "Epoch 13: Loss: 4.937\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.20270270270270271\n",
      "Epoch 14: Loss: 4.911\n",
      "Accuracy of top 1: 0.013513513513513514\n",
      "Accuracy of top 10: 0.20270270270270271\n",
      "Epoch 15: Loss: 4.928\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.22297297297297297\n",
      "Epoch 16: Loss: 4.920\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.20945945945945946\n",
      "Epoch 17: Loss: 4.930\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.19594594594594594\n",
      "Epoch 18: Loss: 4.981\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.19594594594594594\n",
      "Epoch 19: Loss: 4.970\n",
      "Accuracy of top 1: 0.02702702702702703\n",
      "Accuracy of top 10: 0.22297297297297297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    training_set, test_set = create_datasets(sketch_icon_indices, positive_labels, Dataset)\n",
    "    trainloader, testloader = load_dataset()\n",
    "    for _,(indices, labels) in enumerate(trainloader):\n",
    "        i, s = get_batch(indices, icons, sketches)\n",
    "        loss_value = train_step(i, s, labels, margin)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    if epoch%1==0:\n",
    "        acc_1 = 0\n",
    "        acc_10 = 0\n",
    "        sketch_representations = []\n",
    "        for i in range(len(test_sketches)):\n",
    "            sketch_repr =  siameseModel(np.expand_dims(test_sketches[i], 0), training = False)\n",
    "            sketch_representations.append(sketch_repr)\n",
    "        sketch_representations = np.vstack(sketch_representations)\n",
    "\n",
    "        icon_representations = []\n",
    "        for i in range(len(test_icons)):\n",
    "            icon_repr =  siameseModel(np.expand_dims(test_icons[i], 0), training = False)\n",
    "            icon_representations.append(icon_repr)\n",
    "        icon_representations = np.vstack(icon_representations)\n",
    "\n",
    "        for i in range(len(sketch_representations)):\n",
    "            sketch_repr = sketch_representations[i]\n",
    "            sketch_representations_tile = np.tile(sketch_repr, len(test_icons)).reshape(len(test_icons), 256)\n",
    "            diff = np.sqrt(np.mean((sketch_representations_tile - icon_representations)**2, -1))\n",
    "            top_k = np.argsort(diff)[:10]\n",
    "            \n",
    "            for j in range(len(top_k)):\n",
    "                index = top_k[j]\n",
    "                if j == 0 and test_sketch_name[i] == test_icon_name[index]:\n",
    "                    acc_1 = acc_1 + 1\n",
    "                    acc_10 = acc_10 + 1\n",
    "                    break\n",
    "                elif test_sketch_name[i] == test_icon_name[index]:\n",
    "                    acc_10 = acc_10 + 1\n",
    "                    break\n",
    "        print(\"Accuracy of top 1: \" + str(acc_1/len(test_sketches)))\n",
    "        print(\"Accuracy of top 10: \" + str(acc_10/len(test_sketches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}