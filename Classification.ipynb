{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import utils4\n",
    "import model2\n",
    "importlib.reload(utils4)\n",
    "importlib.reload(model2)\n",
    "from utils4 import *\n",
    "from model2 import *\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_name_category, sketch_name_category = get_icons_and_sketches()\n",
    "icon_dictionary, sketch_dictionary = load_icons_sketches_dic(icon_name_category, sketch_name_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 1061 samples in the training set.\nWe have 117 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "icon_categories =  np.unique(icon_name_category[:, 1], return_index=False)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(icon_categories)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "icon_categories_dic = {}\n",
    "for i in range(len(icon_categories)):\n",
    "    icon_categories_dic[icon_categories[i]] = onehot_encoded[i]\n",
    "\n",
    "len_data = len(icon_name_category)\n",
    "p_train=0.9\n",
    "p_test=0.1\n",
    "num_train = int(np.ceil(len_data*p_train))\n",
    "num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "icon_name_category = shuffle(icon_name_category)\n",
    "icons_Train = icon_name_category[:num_train]\n",
    "icons_Test= icon_name_category[-num_test:]\n",
    "\n",
    "print(f'We have {len(icons_Train)} samples in the training set.')\n",
    "print(f'We have {len(icons_Test)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 50\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "iconClassificationModel = mynet(len(icon_categories))\n",
    "loss = compute_cross_entropy\n",
    "def train_step(icons, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = iconClassificationModel(icons, training = True, model = \"Classification\")   \n",
    "        tape.watch(outputs)\n",
    "        current_loss = loss(outputs, targets)\n",
    "    grads = tape.gradient(current_loss, iconClassificationModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, iconClassificationModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer mynet_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mynet_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0: Loss: 4.282\n",
      "Test accuracy is: 0.031409168081494056\n",
      "Epoch 1: Loss: 3.040\n",
      "Test accuracy is: 0.06876061120543293\n",
      "Epoch 2: Loss: 2.121\n",
      "Test accuracy is: 0.07385398981324279\n",
      "Epoch 3: Loss: 1.438\n",
      "Test accuracy is: 0.08743633276740238\n",
      "Epoch 4: Loss: 0.922\n",
      "Test accuracy is: 0.12393887945670629\n",
      "Epoch 5: Loss: 0.567\n",
      "Test accuracy is: 0.1273344651952462\n",
      "Epoch 6: Loss: 0.357\n",
      "Test accuracy is: 0.29796264855687604\n",
      "Epoch 7: Loss: 0.218\n",
      "Test accuracy is: 0.3225806451612903\n",
      "Epoch 8: Loss: 0.134\n",
      "Test accuracy is: 0.37266553480475384\n",
      "Epoch 9: Loss: 0.088\n",
      "Test accuracy is: 0.3370118845500849\n",
      "Epoch 10: Loss: 0.064\n",
      "Test accuracy is: 0.42784380305602715\n",
      "Epoch 11: Loss: 0.054\n",
      "Test accuracy is: 0.38030560271646857\n",
      "Epoch 12: Loss: 0.036\n",
      "Test accuracy is: 0.4083191850594228\n",
      "Epoch 13: Loss: 0.033\n",
      "Test accuracy is: 0.3921901528013582\n",
      "Epoch 14: Loss: 0.028\n",
      "Test accuracy is: 0.39558573853989815\n",
      "Epoch 15: Loss: 0.025\n",
      "Test accuracy is: 0.4295415959252971\n",
      "Epoch 16: Loss: 0.019\n",
      "Test accuracy is: 0.4100169779286927\n",
      "Epoch 17: Loss: 0.020\n",
      "Test accuracy is: 0.4235993208828523\n",
      "Epoch 18: Loss: 0.016\n",
      "Test accuracy is: 0.42529711375212226\n",
      "Epoch 19: Loss: 0.015\n",
      "Test accuracy is: 0.45076400679117146\n",
      "Epoch 20: Loss: 0.013\n",
      "Test accuracy is: 0.4601018675721562\n",
      "Epoch 21: Loss: 0.012\n",
      "Test accuracy is: 0.4796264855687606\n",
      "Epoch 22: Loss: 0.011\n",
      "Test accuracy is: 0.4940577249575552\n",
      "Epoch 23: Loss: 0.010\n",
      "Test accuracy is: 0.5135823429541596\n",
      "Epoch 24: Loss: 0.009\n",
      "Test accuracy is: 0.530560271646859\n",
      "Epoch 25: Loss: 0.009\n",
      "Test accuracy is: 0.5645161290322581\n",
      "Epoch 26: Loss: 0.008\n",
      "Test accuracy is: 0.5882852292020373\n",
      "Epoch 27: Loss: 0.007\n",
      "Test accuracy is: 0.6188455008488964\n",
      "Epoch 28: Loss: 0.007\n",
      "Test accuracy is: 0.6451612903225806\n",
      "Epoch 29: Loss: 0.007\n",
      "Test accuracy is: 0.6748726655348047\n",
      "Epoch 30: Loss: 0.006\n",
      "Test accuracy is: 0.7071307300509337\n",
      "Epoch 31: Loss: 0.006\n",
      "Test accuracy is: 0.7368421052631579\n",
      "Epoch 32: Loss: 0.006\n",
      "Test accuracy is: 0.7724957555178268\n",
      "Epoch 33: Loss: 0.006\n",
      "Test accuracy is: 0.7945670628183361\n",
      "Epoch 34: Loss: 0.005\n",
      "Test accuracy is: 0.8140916808149405\n",
      "Epoch 35: Loss: 0.005\n",
      "Test accuracy is: 0.8505942275042445\n",
      "Epoch 36: Loss: 0.005\n",
      "Test accuracy is: 0.8743633276740238\n",
      "Epoch 37: Loss: 0.005\n",
      "Test accuracy is: 0.8955857385398981\n",
      "Epoch 38: Loss: 0.005\n",
      "Test accuracy is: 0.9185059422750425\n",
      "Epoch 39: Loss: 0.005\n",
      "Test accuracy is: 0.9388794567062818\n",
      "Epoch 40: Loss: 0.005\n",
      "Test accuracy is: 0.9516129032258065\n",
      "Epoch 41: Loss: 0.004\n",
      "Test accuracy is: 0.9711375212224108\n",
      "Epoch 42: Loss: 0.004\n",
      "Test accuracy is: 0.9813242784380306\n",
      "Epoch 43: Loss: 0.004\n",
      "Test accuracy is: 0.9881154499151104\n",
      "Epoch 44: Loss: 0.004\n",
      "Test accuracy is: 0.9949066213921901\n",
      "Epoch 45: Loss: 0.004\n",
      "Test accuracy is: 0.9966044142614601\n",
      "Epoch 46: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 47: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 48: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 49: Loss: 0.004\n",
      "Test accuracy is: 0.99830220713073\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    \n",
    "    for i in range(0, len(icon_name_category), BATCH_SIZE):\n",
    "        icon_name_category_batch = icon_name_category[i:i+BATCH_SIZE]\n",
    "        icons, targets = get_batch_icons_targets(icon_name_category_batch, icon_dictionary, icon_categories_dic)\n",
    "        loss_value = train_step(icons, targets)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    acc = 0\n",
    "    for i in range(0, len(icon_name_category), BATCH_SIZE):\n",
    "        icon_name_category_batch = icon_name_category[i:i+BATCH_SIZE]\n",
    "        icons, targets = get_batch_icons_targets(icon_name_category_batch, icon_dictionary, icon_categories_dic)\n",
    "        outputs = iconClassificationModel(icons, training = False, model = \"Classification\")\n",
    "        correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "        for prediction in correct_prediction:\n",
    "            if prediction:\n",
    "                acc = acc + 1\n",
    "    print(\"Test accuracy is: \" + str(acc/len(icon_name_category)))\n",
    "#iconClassificationModel.save_weights('Training-Weights/iconClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test accuracy is: 0.1282051282051282\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(0, len(icons_Test), BATCH_SIZE):\n",
    "    icon_name_category_batch = icons_Test[i:i+BATCH_SIZE]\n",
    "    icons, targets = get_batch_icons_targets(icon_name_category_batch, icon_dictionary, icon_categories_dic)\n",
    "    outputs = iconClassificationModel(icons, training = False, model = \"Classification\")\n",
    "    correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "    for prediction in correct_prediction:\n",
    "        if prediction:\n",
    "            acc = acc + 1\n",
    "    #print(correct_prediction)\n",
    "print(\"Test accuracy is: \" + str(acc/len(icons_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x20078be66d0>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "iconClassificationModel.load_weights('Training-Weights/iconClassification')"
   ]
  },
  {
   "source": [
    "## Sketch Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 28626 samples in the training set.\nWe have 3180 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "sketch_categories =  np.unique(sketch_name_category[:, 1], return_index=False)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(sketch_categories)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "sketch_categories_dic = {}\n",
    "for i in range(len(sketch_categories)):\n",
    "    sketch_categories_dic[sketch_categories[i]] = onehot_encoded[i]\n",
    "\n",
    "len_data = len(sketch_name_category)\n",
    "p_train=0.9\n",
    "p_test=0.1\n",
    "num_train = int(np.ceil(len_data*p_train))\n",
    "num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "sketch_name_category = shuffle(sketch_name_category)\n",
    "sketches_Train = sketch_name_category[:num_train]\n",
    "sketches_Test= sketch_name_category[-num_test:]\n",
    "\n",
    "print(f'We have {len(sketches_Train)} samples in the training set.')\n",
    "print(f'We have {len(sketches_Test)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "sketchClassificationModel = mynet(len(sketch_categories))\n",
    "loss = compute_cross_entropy\n",
    "def train_step(sketches, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = sketchClassificationModel(sketches, training = True, model = \"Classification\")   \n",
    "        tape.watch(outputs)\n",
    "        current_loss = loss(outputs, targets)\n",
    "    grads = tape.gradient(current_loss, sketchClassificationModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, sketchClassificationModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer mynet_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mynet_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0: Loss: 3.864\n",
      "Test accuracy is: 0.026415094339622643\n",
      "Epoch 1: Loss: 3.225\n",
      "Test accuracy is: 0.016981132075471698\n",
      "Epoch 2: Loss: 2.558\n",
      "Test accuracy is: 0.038679245283018866\n",
      "Epoch 3: Loss: 1.931\n",
      "Test accuracy is: 0.03962264150943396\n",
      "Epoch 4: Loss: 1.377\n",
      "Test accuracy is: 0.03270440251572327\n",
      "Epoch 5: Loss: 0.957\n",
      "Test accuracy is: 0.016981132075471698\n",
      "Epoch 6: Loss: 0.650\n",
      "Test accuracy is: 0.0110062893081761\n",
      "Epoch 7: Loss: 0.457\n",
      "Test accuracy is: 0.028930817610062894\n",
      "Epoch 8: Loss: 0.305\n",
      "Test accuracy is: 0.07641509433962264\n",
      "Epoch 9: Loss: 0.231\n",
      "Test accuracy is: 0.042767295597484274\n",
      "Epoch 10: Loss: 0.159\n",
      "Test accuracy is: 0.024528301886792454\n",
      "Epoch 11: Loss: 0.112\n",
      "Test accuracy is: 0.04905660377358491\n",
      "Epoch 12: Loss: 0.081\n",
      "Test accuracy is: 0.042767295597484274\n",
      "Epoch 13: Loss: 0.064\n",
      "Test accuracy is: 0.07515723270440251\n",
      "Epoch 14: Loss: 0.058\n",
      "Test accuracy is: 0.03993710691823899\n",
      "Epoch 15: Loss: 0.089\n",
      "Test accuracy is: 0.07075471698113207\n",
      "Epoch 16: Loss: 0.179\n",
      "Test accuracy is: 0.012578616352201259\n",
      "Epoch 17: Loss: 0.197\n",
      "Test accuracy is: 0.06666666666666667\n",
      "Epoch 18: Loss: 0.109\n",
      "Test accuracy is: 0.059433962264150944\n",
      "Epoch 19: Loss: 0.051\n",
      "Test accuracy is: 0.04874213836477988\n",
      "Epoch 20: Loss: 0.026\n",
      "Test accuracy is: 0.052515723270440254\n",
      "Epoch 21: Loss: 0.013\n",
      "Test accuracy is: 0.2050314465408805\n",
      "Epoch 22: Loss: 0.003\n",
      "Test accuracy is: 0.33867924528301885\n",
      "Epoch 23: Loss: 0.001\n",
      "Test accuracy is: 0.39905660377358493\n",
      "Epoch 24: Loss: 0.001\n",
      "Test accuracy is: 0.43238993710691825\n",
      "Epoch 25: Loss: 0.001\n",
      "Test accuracy is: 0.4449685534591195\n",
      "Epoch 26: Loss: 0.000\n",
      "Test accuracy is: 0.439622641509434\n",
      "Epoch 27: Loss: 0.000\n",
      "Test accuracy is: 0.4386792452830189\n",
      "Epoch 28: Loss: 0.000\n",
      "Test accuracy is: 0.4641509433962264\n",
      "Epoch 29: Loss: 0.000\n",
      "Test accuracy is: 0.47955974842767296\n",
      "Epoch 30: Loss: 0.000\n",
      "Test accuracy is: 0.48553459119496856\n",
      "Epoch 31: Loss: 0.000\n",
      "Test accuracy is: 0.4889937106918239\n",
      "Epoch 32: Loss: 0.000\n",
      "Test accuracy is: 0.4971698113207547\n",
      "Epoch 33: Loss: 0.000\n",
      "Test accuracy is: 0.49937106918238994\n",
      "Epoch 34: Loss: 0.000\n",
      "Test accuracy is: 0.5044025157232704\n",
      "Epoch 35: Loss: 0.000\n",
      "Test accuracy is: 0.5053459119496856\n",
      "Epoch 36: Loss: 0.000\n",
      "Test accuracy is: 0.5069182389937107\n",
      "Epoch 37: Loss: 0.000\n",
      "Test accuracy is: 0.5066037735849057\n",
      "Epoch 38: Loss: 0.000\n",
      "Test accuracy is: 0.5069182389937107\n",
      "Epoch 39: Loss: 0.000\n",
      "Test accuracy is: 0.5056603773584906\n",
      "Epoch 40: Loss: 0.000\n",
      "Test accuracy is: 0.5078616352201258\n",
      "Epoch 41: Loss: 0.000\n",
      "Test accuracy is: 0.5075471698113208\n",
      "Epoch 42: Loss: 0.000\n",
      "Test accuracy is: 0.509748427672956\n",
      "Epoch 43: Loss: 0.000\n",
      "Test accuracy is: 0.5084905660377359\n",
      "Epoch 44: Loss: 0.000\n",
      "Test accuracy is: 0.5106918238993711\n",
      "Epoch 45: Loss: 0.000\n",
      "Test accuracy is: 0.5081761006289308\n",
      "Epoch 46: Loss: 0.000\n",
      "Test accuracy is: 0.509748427672956\n",
      "Epoch 47: Loss: 0.000\n",
      "Test accuracy is: 0.5088050314465409\n",
      "Epoch 48: Loss: 0.000\n",
      "Test accuracy is: 0.5103773584905661\n",
      "Epoch 49: Loss: 0.000\n",
      "Test accuracy is: 0.5084905660377359\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    sketches_Train = shuffle(sketches_Train)\n",
    "    for i in range(0, len(sketches_Train), BATCH_SIZE):\n",
    "        sketch_name_category_batch = sketches_Train[i:i+BATCH_SIZE]\n",
    "        sketches, targets = get_batch_sketches_targets(sketch_name_category_batch, sketch_dictionary, sketch_categories_dic)\n",
    "        loss_value = train_step(sketches, targets)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    acc = 0\n",
    "    for i in range(0, len(sketches_Test), BATCH_SIZE):\n",
    "        sketch_name_category_batch = sketches_Test[i:i+BATCH_SIZE]\n",
    "        sketches, targets = get_batch_sketches_targets(sketch_name_category_batch, sketch_dictionary, sketch_categories_dic)\n",
    "        outputs = sketchClassificationModel(sketches, training = False, model = \"Classification\")\n",
    "        correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "        for prediction in correct_prediction:\n",
    "            if prediction:\n",
    "                acc = acc + 1\n",
    "    print(\"Test accuracy is: \" + str(acc/len(sketches_Test)))\n",
    "#iconClassificationModel.save_weights('Training-Weights/iconClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketchClassificationModel.save_weights('Training-Weights/sketchClassification2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}