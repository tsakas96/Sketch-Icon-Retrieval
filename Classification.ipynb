{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import utils4\n",
    "import model2\n",
    "import results_generator\n",
    "importlib.reload(utils4)\n",
    "importlib.reload(model2)\n",
    "importlib.reload(results_generator)\n",
    "from utils4 import *\n",
    "from model2 import *\n",
    "from results_generator import *\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_name_category, sketch_name_category = get_icons_and_sketches()\n",
    "icon_dictionary, sketch_dictionary = load_icons_sketches_dic(icon_name_category, sketch_name_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 1061 samples in the training set.\nWe have 117 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "icon_categories =  np.unique(icon_name_category[:, 1], return_index=False)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(icon_categories)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "icon_categories_dic = {}\n",
    "for i in range(len(icon_categories)):\n",
    "    icon_categories_dic[icon_categories[i]] = onehot_encoded[i]\n",
    "\n",
    "len_data = len(icon_name_category)\n",
    "p_train=0.9\n",
    "p_test=0.1\n",
    "num_train = int(np.ceil(len_data*p_train))\n",
    "num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "icon_name_category = shuffle(icon_name_category)\n",
    "icons_Train = icon_name_category[:num_train]\n",
    "icons_Test= icon_name_category[-num_test:]\n",
    "\n",
    "print(f'We have {len(icons_Train)} samples in the training set.')\n",
    "print(f'We have {len(icons_Test)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MyNet\"\n",
    "algorithm_name = \"Icon Classification\"\n",
    "create_directory(model_name + \"/\")\n",
    "now = datetime.now()\n",
    "date_time_folder = now.strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "train_weights_folder = \"Train Weights\"\n",
    "create_directory(model_name + \"/\" + algorithm_name)\n",
    "current_run_path = model_name + \"/\" + algorithm_name + \"/\" + date_time_folder + \"/\"\n",
    "create_directory(current_run_path)\n",
    "train_weights_path = model_name + \"/\" + algorithm_name + \"/\" + date_time_folder + \"/\" + train_weights_folder\n",
    "create_directory(train_weights_path)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 50\n",
    "learing_rate = 0.001\n",
    "write_classification_hyperparameters_in_file(current_run_path, learing_rate, BATCH_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam(learing_rate)\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "iconClassificationModel = mynet(len(icon_categories))\n",
    "loss = compute_cross_entropy\n",
    "def train_step(icons, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, outputs = iconClassificationModel(icons, training = True)   \n",
    "        tape.watch(outputs)\n",
    "        current_loss = loss(outputs, targets)\n",
    "    grads = tape.gradient(current_loss, iconClassificationModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, iconClassificationModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer mynet_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mynet_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0: Loss: 4.282\n",
      "Test accuracy is: 0.031409168081494056\n",
      "Epoch 1: Loss: 3.040\n",
      "Test accuracy is: 0.06876061120543293\n",
      "Epoch 2: Loss: 2.121\n",
      "Test accuracy is: 0.07385398981324279\n",
      "Epoch 3: Loss: 1.438\n",
      "Test accuracy is: 0.08743633276740238\n",
      "Epoch 4: Loss: 0.922\n",
      "Test accuracy is: 0.12393887945670629\n",
      "Epoch 5: Loss: 0.567\n",
      "Test accuracy is: 0.1273344651952462\n",
      "Epoch 6: Loss: 0.357\n",
      "Test accuracy is: 0.29796264855687604\n",
      "Epoch 7: Loss: 0.218\n",
      "Test accuracy is: 0.3225806451612903\n",
      "Epoch 8: Loss: 0.134\n",
      "Test accuracy is: 0.37266553480475384\n",
      "Epoch 9: Loss: 0.088\n",
      "Test accuracy is: 0.3370118845500849\n",
      "Epoch 10: Loss: 0.064\n",
      "Test accuracy is: 0.42784380305602715\n",
      "Epoch 11: Loss: 0.054\n",
      "Test accuracy is: 0.38030560271646857\n",
      "Epoch 12: Loss: 0.036\n",
      "Test accuracy is: 0.4083191850594228\n",
      "Epoch 13: Loss: 0.033\n",
      "Test accuracy is: 0.3921901528013582\n",
      "Epoch 14: Loss: 0.028\n",
      "Test accuracy is: 0.39558573853989815\n",
      "Epoch 15: Loss: 0.025\n",
      "Test accuracy is: 0.4295415959252971\n",
      "Epoch 16: Loss: 0.019\n",
      "Test accuracy is: 0.4100169779286927\n",
      "Epoch 17: Loss: 0.020\n",
      "Test accuracy is: 0.4235993208828523\n",
      "Epoch 18: Loss: 0.016\n",
      "Test accuracy is: 0.42529711375212226\n",
      "Epoch 19: Loss: 0.015\n",
      "Test accuracy is: 0.45076400679117146\n",
      "Epoch 20: Loss: 0.013\n",
      "Test accuracy is: 0.4601018675721562\n",
      "Epoch 21: Loss: 0.012\n",
      "Test accuracy is: 0.4796264855687606\n",
      "Epoch 22: Loss: 0.011\n",
      "Test accuracy is: 0.4940577249575552\n",
      "Epoch 23: Loss: 0.010\n",
      "Test accuracy is: 0.5135823429541596\n",
      "Epoch 24: Loss: 0.009\n",
      "Test accuracy is: 0.530560271646859\n",
      "Epoch 25: Loss: 0.009\n",
      "Test accuracy is: 0.5645161290322581\n",
      "Epoch 26: Loss: 0.008\n",
      "Test accuracy is: 0.5882852292020373\n",
      "Epoch 27: Loss: 0.007\n",
      "Test accuracy is: 0.6188455008488964\n",
      "Epoch 28: Loss: 0.007\n",
      "Test accuracy is: 0.6451612903225806\n",
      "Epoch 29: Loss: 0.007\n",
      "Test accuracy is: 0.6748726655348047\n",
      "Epoch 30: Loss: 0.006\n",
      "Test accuracy is: 0.7071307300509337\n",
      "Epoch 31: Loss: 0.006\n",
      "Test accuracy is: 0.7368421052631579\n",
      "Epoch 32: Loss: 0.006\n",
      "Test accuracy is: 0.7724957555178268\n",
      "Epoch 33: Loss: 0.006\n",
      "Test accuracy is: 0.7945670628183361\n",
      "Epoch 34: Loss: 0.005\n",
      "Test accuracy is: 0.8140916808149405\n",
      "Epoch 35: Loss: 0.005\n",
      "Test accuracy is: 0.8505942275042445\n",
      "Epoch 36: Loss: 0.005\n",
      "Test accuracy is: 0.8743633276740238\n",
      "Epoch 37: Loss: 0.005\n",
      "Test accuracy is: 0.8955857385398981\n",
      "Epoch 38: Loss: 0.005\n",
      "Test accuracy is: 0.9185059422750425\n",
      "Epoch 39: Loss: 0.005\n",
      "Test accuracy is: 0.9388794567062818\n",
      "Epoch 40: Loss: 0.005\n",
      "Test accuracy is: 0.9516129032258065\n",
      "Epoch 41: Loss: 0.004\n",
      "Test accuracy is: 0.9711375212224108\n",
      "Epoch 42: Loss: 0.004\n",
      "Test accuracy is: 0.9813242784380306\n",
      "Epoch 43: Loss: 0.004\n",
      "Test accuracy is: 0.9881154499151104\n",
      "Epoch 44: Loss: 0.004\n",
      "Test accuracy is: 0.9949066213921901\n",
      "Epoch 45: Loss: 0.004\n",
      "Test accuracy is: 0.9966044142614601\n",
      "Epoch 46: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 47: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 48: Loss: 0.004\n",
      "Test accuracy is: 0.9974533106960951\n",
      "Epoch 49: Loss: 0.004\n",
      "Test accuracy is: 0.99830220713073\n"
     ]
    }
   ],
   "source": [
    "top_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    # I am using all the icons for training because i want to overfit the training\n",
    "    for i in range(0, len(icon_name_category), BATCH_SIZE):\n",
    "        icon_name_category_batch = icon_name_category[i:i+BATCH_SIZE]\n",
    "        icons, targets = get_batch_icons_targets(icon_name_category_batch, icon_dictionary, icon_categories_dic)\n",
    "        loss_value = train_step(icons, targets)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    acc = 0\n",
    "    for i in range(0, len(icon_name_category), BATCH_SIZE):\n",
    "        icon_name_category_batch = icon_name_category[i:i+BATCH_SIZE]\n",
    "        icons, targets = get_batch_icons_targets(icon_name_category_batch, icon_dictionary, icon_categories_dic)\n",
    "        _, outputs = iconClassificationModel(icons, training = False)\n",
    "        correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "        for prediction in correct_prediction:\n",
    "            if prediction:\n",
    "                acc = acc + 1\n",
    "    if top_acc<acc:\n",
    "        top_acc = acc\n",
    "        save_weights(iconClassificationModel, train_weights_path + \"/iconClassification\")\n",
    "\n",
    "    write_classification_stats_in_file(current_run_path, epoch, epoch_loss_avg.result(), acc/len(icon_name_category))\n",
    "    print(\"Test accuracy is: \" + str(acc/len(icon_name_category)))\n"
   ]
  },
  {
   "source": [
    "## Sketch Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 28626 samples in the training set.\nWe have 3180 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "sketch_categories =  np.unique(sketch_name_category[:, 1], return_index=False)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(sketch_categories)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "sketch_categories_dic = {}\n",
    "for i in range(len(sketch_categories)):\n",
    "    sketch_categories_dic[sketch_categories[i]] = onehot_encoded[i]\n",
    "\n",
    "random_generation = False\n",
    "if random_generation:\n",
    "    len_data = len(sketch_name_category)\n",
    "    p_train=0.9\n",
    "    p_test=0.1\n",
    "    num_train = int(np.ceil(len_data*p_train))\n",
    "    num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "    sketch_name_category = shuffle(sketch_name_category)\n",
    "    sketches_Train = sketch_name_category[:num_train]\n",
    "    sketches_Test= sketch_name_category[-num_test:]\n",
    "else:\n",
    "    sketches_Train = load_train_set()\n",
    "    sketches_Train = shuffle(sketches_Train)\n",
    "    sketches_Test = load_test_set()\n",
    "\n",
    "print(f'We have {len(sketches_Train)} samples in the training set.')\n",
    "print(f'We have {len(sketches_Test)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creation of the directory  failedMyNet/\nSuccessfully created the directory  MyNet/Sketch Classification\nSuccessfully created the directory  MyNet/Sketch Classification/21-03-2021 16-09-55/\nSuccessfully created the directory  MyNet/Sketch Classification/21-03-2021 16-09-55/Train Weights\n"
     ]
    }
   ],
   "source": [
    "model_name = \"MyNet\"\n",
    "algorithm_name = \"Sketch Classification\"\n",
    "create_directory(model_name + \"/\")\n",
    "now = datetime.now()\n",
    "date_time_folder = now.strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "train_weights_folder = \"Train Weights\"\n",
    "create_directory(model_name + \"/\" + algorithm_name)\n",
    "current_run_path = model_name + \"/\" + algorithm_name + \"/\" + date_time_folder + \"/\"\n",
    "create_directory(current_run_path)\n",
    "train_weights_path = model_name + \"/\" + algorithm_name + \"/\" + date_time_folder + \"/\" + train_weights_folder\n",
    "create_directory(train_weights_path)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 100\n",
    "learing_rate = 0.001\n",
    "write_classification_hyperparameters_in_file(current_run_path, learing_rate, BATCH_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam(learing_rate)\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "sketchClassificationModel = mynet(len(sketch_categories))\n",
    "loss = compute_cross_entropy\n",
    "def train_step(sketches, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, outputs = sketchClassificationModel(sketches, training = True)   \n",
    "        tape.watch(outputs)\n",
    "        current_loss = loss(outputs, targets)\n",
    "    grads = tape.gradient(current_loss, sketchClassificationModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, sketchClassificationModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer mynet is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fa145dce29f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msketch_name_category_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msketches_Train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msketches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch_sketches_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msketch_name_category_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msketch_dictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msketch_categories_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msketches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mepoch_loss_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {:d}: Loss: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch_loss_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-415bad21ae3f>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(sketches, targets)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msketches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msketchClassificationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msketches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Classification\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\arist\\Desktop\\Thesis\\Sketch-Icon-Retrieval\\model2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training, model)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_max_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m     name=None):\n\u001b[1;32m-> 1011\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1012\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1142\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2586\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    936\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programming\\ThesisModelsCuda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "sketches_Train = shuffle(sketches_Train)\n",
    "top_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    \n",
    "    for i in range(0, len(sketches_Train), BATCH_SIZE):\n",
    "        sketch_name_category_batch = sketches_Train[i:i+BATCH_SIZE]\n",
    "        sketches, targets = get_batch_sketches_targets(sketch_name_category_batch, sketch_dictionary, sketch_categories_dic)\n",
    "        loss_value = train_step(sketches, targets)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    acc = 0\n",
    "    for i in range(0, len(sketches_Test), BATCH_SIZE):\n",
    "        sketch_name_category_batch = sketches_Test[i:i+BATCH_SIZE]\n",
    "        sketches, targets = get_batch_sketches_targets(sketch_name_category_batch, sketch_dictionary, sketch_categories_dic)\n",
    "        _, outputs = sketchClassificationModel(sketches, training = False)\n",
    "        correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(targets,1))\n",
    "        for prediction in correct_prediction:\n",
    "            if prediction:\n",
    "                acc = acc + 1\n",
    "    if top_acc<acc:\n",
    "        top_acc = acc\n",
    "        save_weights(sketchClassificationModel, train_weights_path + \"/sketchClassification\")\n",
    "    print(\"Test accuracy is: \" + str(acc/len(sketches_Test)))\n",
    "    write_classification_stats_in_file(current_run_path, epoch, epoch_loss_avg.result(), acc/len(sketches_Test))\n",
    "\n",
    "print(\"The best accuracy is: \" + str(top_acc/len(sketches_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}