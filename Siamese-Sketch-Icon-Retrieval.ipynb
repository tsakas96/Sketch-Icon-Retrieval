{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import utils\n",
    "import model2\n",
    "importlib.reload(utils)\n",
    "importlib.reload(model2)\n",
    "from utils import *\n",
    "from model2 import *\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 1708 samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic = get_dict_icon_sketches()\n",
    "\n",
    "icons, icons_name_cat = load_icons(dic)\n",
    "sketches, sketch_names_array = load_sketches(dic)\n",
    "\n",
    "sketch_icon_indices, positive_labels = create_positive_sketch_icon_indices(icons_name_cat, sketch_names_array)\n",
    "print(f'We have {len(sketch_icon_indices)} samples.')\n",
    "# shuffle the indices and labels\n",
    "sketch_icon_indices, positive_labels = shuffle(sketch_icon_indices, positive_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 1367 positive pair samples in the training set.\nWe have 1367 negative pair samples in the training set.\nWe have 2734 samples in the training set.\nWe have 341 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "NEGATIVE_PAIRS_LEN = 1\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, indices, labels):\n",
    "        self.indices = indices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve indices and labels at the given index\n",
    "        indices = self.indices[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return indices, label\n",
    "\n",
    "def create_datasets(sketch_icon_indices, labels, dataset_class, p_train=0.8, p_test=0.2):\n",
    "    len_data = len(sketch_icon_indices)\n",
    "\n",
    "    # Define partition sizes\n",
    "    num_train = int(np.ceil(len_data*p_train))\n",
    "    num_test = int(np.floor(len_data*p_test))\n",
    "\n",
    "    sketch_icon_indices_Train, positive_labels_Train = sketch_icon_indices[:num_train], labels[:num_train]\n",
    "    sketch_icon_indices_Test, labels_test = sketch_icon_indices[-num_test:], labels[-num_test:]\n",
    "\n",
    "    negative_indices, negative_labels_Train = create_negative_sketch_icon_indices(sketch_icon_indices_Train, NEGATIVE_PAIRS_LEN)\n",
    "    print(f'We have {len(sketch_icon_indices_Train)} positive pair samples in the training set.')\n",
    "    print(f'We have {len(negative_indices)} negative pair samples in the training set.')\n",
    "\n",
    "    negative_array = np.array(negative_indices)\n",
    "    # This array includes the posititive and negative pair indices\n",
    "    pair_indices_Train = np.concatenate((sketch_icon_indices_Train, negative_array), axis=0)\n",
    "    labels_Train = np.concatenate((positive_labels_Train, negative_labels_Train), axis=0)\n",
    "\n",
    "    training_set = dataset_class(pair_indices_Train, labels_Train)\n",
    "    test_set = dataset_class(sketch_icon_indices_Test, labels_test)\n",
    "    return training_set, test_set\n",
    "\n",
    "training_set, test_set = create_datasets(sketch_icon_indices, positive_labels, Dataset)   \n",
    "print(f'We have {len(training_set)} samples in the training set.')\n",
    "print(f'We have {len(test_set)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def load_dataset():\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "      dataset = training_set,\n",
    "      batch_size= batch_size,\n",
    "      num_workers = 0,\n",
    "      shuffle= True\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "      dataset = test_set,\n",
    "      batch_size= batch_size,\n",
    "      num_workers= 0,\n",
    "      shuffle= False\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "margin = 1\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "siameseModel = mynet()\n",
    "loss = siamese_loss\n",
    "\n",
    "def train_step( icons, sketches , labels, margin):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model1 = siameseModel(icons)\n",
    "        model2 = siameseModel(sketches)    \n",
    "        tape.watch(model1)\n",
    "        tape.watch(model2)\n",
    "        labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "        tape.watch(labels)\n",
    "        current_loss = loss(model1, model2, labels)\n",
    "    grads = tape.gradient(current_loss, siameseModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, siameseModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_icon_indeces = set()\n",
    "test_sketch_indices = set()\n",
    "sketch_index = 0\n",
    "for s, i in test_set.indices:\n",
    "    test_sketch_indices.add(s)\n",
    "    test_icon_indeces.add(i)\n",
    "\n",
    "sketch_index =  np.random.choice(list(test_sketch_indices))\n",
    "\n",
    "\n",
    "test_sketch_list = []\n",
    "for s in test_sketch_indices:\n",
    "    test_sketch_list.append(sketches[s])\n",
    "test_sketches = np.array(test_sketch_list)\n",
    "print(test_sketches.shape)\n",
    "\n",
    "test_icon_list = []\n",
    "for i in test_icon_indeces:\n",
    "    test_icon_list.append(icons[i])\n",
    "test_icons = np.array(test_icon_list)\n",
    "print(test_icons.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "Epoch 0: Loss: 4.925\n",
      "(1, 64)\n",
      "(97, 64)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_icon_paths' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-675acc09a619>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_icon_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_icon_paths' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count = 0\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    for _,(indices, labels) in enumerate(trainloader):\n",
    "        i, s = get_batch(indices, icons, sketches)\n",
    "        loss_value = train_step(i, s, labels, margin)\n",
    "        epoch_loss_avg.update_state(loss_value)\n",
    "        count = count + 1\n",
    "        print(count)\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    if epoch%1==0:\n",
    "    \n",
    "        sketch_repr = siameseModel(test_sketch)\n",
    "        print(sketch_repr.shape)\n",
    "        sketch_representations = np.tile(sketch_repr, len(test_icons)).reshape(len(test_icons), 64)\n",
    "        print(sketch_representations.shape)\n",
    "        \n",
    "        icon_representations = []\n",
    "        for i in range(len(test_icons)):\n",
    "            icon_repr =  siameseModel(np.expand_dims(test_icons[i], 0))\n",
    "            icon_representations.append(icon_repr)\n",
    "        icon_representations = np.vstack(icon_representations)\n",
    "\n",
    "        diff = np.sqrt(np.mean((sketch_representations - icon_representations)**2, -1))\n",
    "        \n",
    "        top_k = np.argsort(diff)[:20]\n",
    "        #print ('##' + str(epoch) + ' : loss == ' + str(loss_))\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i in range(20):    \n",
    "            plt.subplot(1, 20, i+1)\n",
    "            plt.imshow(test_icons[top_k[i]])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tf.Tensor: shape=(64, 64), dtype=float64, numpy=\narray([[2.10307419, 2.6668619 , 1.78483691, ..., 0.        , 0.62975157,\n        3.40164434],\n       [0.47681311, 2.03457366, 0.52009692, ..., 0.        , 0.17091979,\n        3.24607072],\n       [0.53815468, 0.85331889, 1.26350414, ..., 0.45346822, 0.19618425,\n        1.12554009],\n       ...,\n       [0.59875619, 0.98671885, 1.54649492, ..., 0.29101804, 1.01481024,\n        2.06775315],\n       [0.        , 1.36345521, 1.74281345, ..., 0.        , 0.        ,\n        3.36829235],\n       [1.18102268, 1.15978806, 0.58786593, ..., 0.54116972, 0.        ,\n        1.63186885]])>, <tf.Tensor: shape=(64, 64), dtype=float64, numpy=\narray([[1.15959765, 2.79862226, 0.86213758, ..., 0.        , 0.078685  ,\n        2.94678881],\n       [1.18102268, 1.15978806, 0.58786593, ..., 0.54116972, 0.        ,\n        1.63186885],\n       [1.03804092, 1.74221365, 0.34843403, ..., 0.        , 0.18176409,\n        3.55290126],\n       ...,\n       [1.95794444, 1.67133414, 2.20675695, ..., 0.        , 0.        ,\n        2.63612619],\n       [1.03884855, 1.0345716 , 1.43945912, ..., 0.        , 0.        ,\n        2.55581329],\n       [1.21506836, 2.11553634, 1.85838455, ..., 0.        , 0.        ,\n        3.37758494]])>, <tf.Tensor: shape=(64, 64), dtype=float64, numpy=\narray([[1.57847379, 2.43326739, 0.29555697, ..., 0.        , 0.47678827,\n        3.68051274],\n       [1.18102268, 1.15978806, 0.58786593, ..., 0.54116972, 0.        ,\n        1.63186885],\n       [1.95794444, 1.67133414, 2.20675695, ..., 0.        , 0.        ,\n        2.63612619],\n       ...,\n       [1.94877745, 2.8228575 , 1.97721164, ..., 0.        , 0.34872268,\n        2.99659759],\n       [2.0876341 , 0.52549554, 1.44613401, ..., 0.        , 0.        ,\n        2.22786524],\n       [0.05225422, 1.06952828, 0.15070428, ..., 0.2865139 , 0.        ,\n        2.25041779]])>, <tf.Tensor: shape=(64, 64), dtype=float64, numpy=\narray([[0.40710897, 2.27249371, 1.18104816, ..., 0.        , 0.90164582,\n        2.9180459 ],\n       [0.        , 1.67520505, 1.0040907 , ..., 0.        , 0.51451424,\n        2.30482827],\n       [0.56680944, 1.94286738, 0.87940865, ..., 0.        , 0.68216306,\n        2.3729294 ],\n       ...,\n       [0.75011796, 1.86932779, 0.99725181, ..., 0.        , 0.12029563,\n        3.18050714],\n       [0.14973007, 2.24441968, 1.0155106 , ..., 0.36262606, 0.        ,\n        2.86463661],\n       [0.17368139, 1.86639668, 0.        , ..., 0.        , 0.        ,\n        2.56068041]])>, <tf.Tensor: shape=(64, 64), dtype=float64, numpy=\narray([[0.47681311, 2.03457366, 0.52009692, ..., 0.        , 0.17091979,\n        3.24607072],\n       [0.        , 0.04148434, 0.60272393, ..., 0.12239   , 0.03218383,\n        0.18458875],\n       [1.49565116, 2.07543977, 2.23771995, ..., 0.        , 0.        ,\n        2.75825368],\n       ...,\n       [1.22665267, 2.04473177, 1.69858067, ..., 0.        , 1.05867574,\n        3.31568486],\n       [0.17368139, 1.86639668, 0.        , ..., 0.        , 0.        ,\n        2.56068041],\n       [1.11252619, 1.39082442, 0.19988763, ..., 0.        , 0.        ,\n        3.03543429]])>, <tf.Tensor: shape=(21, 64), dtype=float64, numpy=\narray([[1.08324211, 1.49831865, 1.36725027, ..., 0.5112863 , 0.15103247,\n        2.70920686],\n       [0.75898343, 2.21948543, 2.35484582, ..., 0.        , 1.15614135,\n        2.99675894],\n       [0.26240929, 2.43675759, 0.18444429, ..., 0.64293256, 0.        ,\n        2.57135081],\n       ...,\n       [1.78603628, 2.55424403, 1.1209475 , ..., 0.        , 0.83797886,\n        2.70066838],\n       [0.27989216, 0.90826479, 0.73659894, ..., 0.93768265, 0.14485378,\n        2.0830449 ],\n       [1.82612789, 2.4248006 , 1.14894141, ..., 0.        , 0.81661995,\n        3.04450183]])>]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}