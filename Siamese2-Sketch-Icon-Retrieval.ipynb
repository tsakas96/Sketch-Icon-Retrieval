{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import utils2\n",
    "import model2\n",
    "importlib.reload(utils2)\n",
    "importlib.reload(model2)\n",
    "from utils2 import *\n",
    "from model2 import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Sketch-Icon-Dataset/\"\n",
    "icon_path = os.path.join(dataset_path, 'icon/')\n",
    "sketch_path = os.path.join(dataset_path, 'sketch/')\n",
    "\n",
    "icon_sketch_dic = get_dict_icon_sketches()\n",
    "icon_sketch_dic_TRAIN = copy.deepcopy(icon_sketch_dic)\n",
    "icon_sketch_dic_TEST = {}\n",
    "\n",
    "NUM_TEST_SKETCHES = 1\n",
    "\n",
    "\n",
    "for icon in icon_sketch_dic.keys():\n",
    "    sketch_list = []\n",
    "    for i in range(0, NUM_TEST_SKETCHES):\n",
    "        sketch = np.random.choice(icon_sketch_dic[icon][1])\n",
    "        sketch_list.append(sketch)\n",
    "        icon_sketch_dic_TRAIN[icon][1].remove(sketch)\n",
    "    icon_sketch_dic_TEST[icon] = (icon_sketch_dic[icon][0], sketch_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sketch-Icon-Dataset/sketch/construction/hammer_9.png\n"
     ]
    }
   ],
   "source": [
    "icon_name = np.random.choice(list(icon_sketch_dic_TEST.keys()))\n",
    "test_sketch_name, category = np.random.choice(icon_sketch_dic_TEST[icon_name][1]), icon_sketch_dic_TEST[icon_name][0]\n",
    "test_sketch_path = sketch_path + category + '/' + test_sketch_name\n",
    "print(test_sketch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 100, 100, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "test_sketch = load_img(test_sketch_path)\n",
    "test_sketch = np.expand_dims(test_sketch, 0)\n",
    "test_sketch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100, 100, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "test_icons = []\n",
    "test_icon_paths = []\n",
    "for icon, (category,_) in icon_sketch_dic_TEST.items():\n",
    "    path = icon_path + category + '/' + icon\n",
    "    test_icons.append(load_img(path))\n",
    "    test_icon_paths.append(path)\n",
    "test_icons = np.array(test_icons)\n",
    "test_icons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=256x256 at 0x1FE54D12790>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAG/klEQVR4nO3d2ZLiOBBAUeio//9l5sE1NM1S5UWSlZnnPE30RFAYdCUZDFxvt9ulj+v12u/GoYmvHjd6vV573Cw01z6Ax4nfIsDk/rS9OSOeWJqtAMu2x+gnljYrwDLxv47+2+3mfICZNQjAtoe4Dm2BbHuIbv8K8Gnb88QuiJntDMC2hxwavwwKsewJYOv0bxfEtDYHYPNDJrZAlLYtgN3Tv10Qc9oQgM0P+YzbAi2LgHWAqayd1I9P/5uGvqWGMVZdCtFk9D/ewq/XUDzWIgb66fKJsF8tY/qHrl5ref13OO73qb359P/0vy5bhrUYaOuXwd119B/8K2LguHO2QE3YJnHcT1Nvqxf++y0Cn27q/t9i4GcfV4C4b3tZGVjv/ShvPvoHLwKfbv/+32JgEfgcYCsrA6/eBHDW5me5VmLMn34bgxIKeg6g0xAcObi3evweu9d/JLe5tkDndmKPVNA/AUw7SY8nhiKGfpHtyj8xc4diSGauLdD8rAzJfAcwZtKd+VR4BzEk8HWZe8sRhRiCsgVqTwyBfJn+uxLD5KwA43j7eUICOIe3nychgJPZI51LABMRw3gCmJQYxhBAAGLo5yvZu7PpiaEtK0BgYjhOAEmIYR8BJCSG9QSQ3KbvJC5IAIXcv5P4IoP/CaAcGTwSQFEyWAigNBkIgNIZCIBvNTMQAP+olsGfi1+x5sXtdivys7ZWAD6qsBqM+6Hs9axIU7mvBmffkS5mDIAJZW1AAJQmANZKuQgMDcBHz5iNFYAN8i0C3wHkOzBYY9wKYP+TQ7K58m8AyQ4M1hi0Apj+M8k0V/5zKcT9wBoO1jSPFCk9XwvU5PIP30SQXprvU3t/Mdy+DHznPeH8dDXopgxyzAesl2MR+P0kuM6l4WyV4Gx47ecBHleDx39ZJJgJqGnbB2J85x5Pom+E9n8iLO4xw52L4Tgq9JmAAChNADQQdxEQAKUJgDaCLgICoDQB0EzERWDSAFx8wRizv4eX+3v5Uor1xvCkK8Bd7u/l43SzB7CwI6KTSKvVxY5oerH2P5dwX49e4Qu7B9i6liZ+qIP1+ijcZDOVTY/epmBiPSmxx5Cl4AgzyCV6AAsZ7KaBGK8C/cxLpbt53DIEsPBS6T7FG0i4AtoR7VB2L5T2sGWwVc0Gkh9zzSd1t4KzRv7xMdWT+na3Pcl9uys1a1Q51EkyeDu2Pp2Dnnhv6zRQ5TgXpz+vO95/PesOn/5YjZHnZdA1Yr1Ueu63shZ5ebRE5a/Omlx3T6vh7nAUyQ/vZ+Of3YN/8ZRfYMjdQOZjW2PwzNpqMAW92xNKe2CbDBtPbUfSyAyyNhDsAzFr7Hiqgn7OJujdnkq2AI5MVPfxFGswPf12Saw7f7psARzX47diB7jf2x53PtyksF6qAFo9T6G3FqHv/Hh5Amg+SwXdES1ksFKeADoJPXpef9rwEvyImksSQNB5eoynR2brFam5H9sMAeR+hpp7+1i9VlHkIc0QAMetv0g7mfABmP47KfKoxr4c2ujnoMABGP0cFziAcBQ7oagBGEw0ETIAo59WQgYArcQLwPRPQ/ECgIYEQGnBArD/oa1gAUBbAqA0AVBapACcANBcpACgOQFQmgAoTQCUFiYAZ8D0ECYA6EEAlCYASosRgBMAOokRAHQiAEoTAKUJgNICBOAMmH4CBAD9CIDSBEBpswfgBICuZg8AuhIApQmA0qYOwAkAvU0dAPQmAEoTAKUJgNLmDSDZGXCyw0lj3gBgAAFQmgAobdIA7JgZY9IAYAwBUJoAKE0AlDZjAM6AGWbGAGAYAVCaAChtugCcADDSdAHASAKgNAFQmgAoTQCUJgBKEwClzRVA1jcBsh5XAnMFAIMJoDvT/8wEQGkCoDQB9GX/MzkBUJoAOjL9z08AlCYASpsogGQbhmSHk9VEAcB4AujC9B+FAChNAJQmgPbsfwIRAKUJoDHTfywCoDQBUJoAWrL/CUcAlCaAZkz/EQmA0gRAaQJow/4nKAFQmgAaMP3HJQBKEwClCeAo+5/QBEBpAjjE9B+dAChNAJQmgP3sfxIQAKUJYCfTfw4CoDQB7GH6T0MAlCaAzUz/mQiA0gSwjek/GQFQmgA2MP3nI4C1jP6UBEBpAljF9J+VAChNAL8z/ScmAEoTwC9M/7kJ4CdGf3oCoDQBfGT6r0AAlCaA90z/RQjgDaO/DgFQmgCemf5LEQClCeAfpv9qBEBpAvjL9F+QAL4Z/TUJgNIEcLmY/gsTAKUJwPRfmgAorXoApv/iSgdg9DNXANfrdeTfMvr5OvsO/LUMx8cGDFB6m3oWvMfQ/E6a/lnEGAdtSzD6uQs2FI5vkIx+Hk10DrDG49jtt0GijgzT4afXjl4PzfTPk8wD4jWMxAfLPv8B4sxahpTpoj8AAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open(test_sketch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "BATCH_SIZE = 128\n",
    "margin = 1\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "siameseModel = mynet()\n",
    "loss = siamese_loss\n",
    "\n",
    "def train_step( icons, sketches , labels, margin):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model1 = siameseModel(icons)\n",
    "        model2 = siameseModel(sketches)    \n",
    "        tape.watch(model1)\n",
    "        tape.watch(model2)\n",
    "        labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "        tape.watch(labels)\n",
    "        #current_loss = loss(model1, model2, labels, margin)\n",
    "        current_loss = loss(model1, model2, labels)\n",
    "    grads = tape.gradient(current_loss, siameseModel.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, siameseModel.trainable_variables))\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "siamese_loss() takes 3 positional arguments but 4 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-87d429b0e458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepoch_loss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0micon_sketch_dic_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mepoch_loss_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-36a2fce55873>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(icons, sketches, labels, margin)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiameseModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiameseModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: siamese_loss() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "#weights = []\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    i, s, labels = get_batch(icon_sketch_dic_TRAIN, BATCH_SIZE)\n",
    "    loss_value = train_step(i, s, labels, margin)\n",
    "    epoch_loss_avg.update_state(loss_value)\n",
    "\n",
    "    print(\"Epoch {:d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))\n",
    "    #weights.append(siameseModel.trainable_variables)\n",
    "    if epoch%5==0:\n",
    "    \n",
    "        sketch_repr = siameseModel(test_sketch)\n",
    "        print(sketch_repr.shape)\n",
    "        sketch_representations = np.tile(sketch_repr, len(test_icons)).reshape(len(test_icons), 64)\n",
    "        print(sketch_representations.shape)\n",
    "        \n",
    "        icon_representations = []\n",
    "        for i in range(len(test_icons)):\n",
    "            icon_repr =  siameseModel(np.expand_dims(test_icons[i], 0))\n",
    "            icon_representations.append(icon_repr)\n",
    "        icon_representations = np.vstack(icon_representations)\n",
    "\n",
    "        diff = np.sqrt(np.mean((sketch_representations - icon_representations)**2, -1))\n",
    "        \n",
    "        top_k = np.argsort(diff)[:20]\n",
    "        #print ('##' + str(epoch) + ' : loss == ' + str(loss_))\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i in range(20):    \n",
    "            img = mpimg.imread(test_icon_paths[top_k[i]])\n",
    "            plt.subplot(1, 20, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}